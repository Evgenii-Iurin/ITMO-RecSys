{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7045350c",
   "metadata": {},
   "source": [
    "In this seminar, you've explored a basic implementation of the Deep Structured Semantic Model (DSSM).\n",
    "\n",
    "Your task is to **improve this model** in one or more of the following directions:\n",
    "\n",
    "### ‚úÖ Model Improvements\n",
    "- [ ] Replace MLP towers with Transformer or RNN encoders or etc. (5 –±–∞–ª–ª–æ–≤)\n",
    "- [x] Use different triplet loss. (3 –±–∞–ª–ª–∞)\n",
    "- [x] Add dropout, batch normalization, or layer norm. (3 –±–∞–ª–ª–∞)\n",
    "- [x] Integrate embeddings instead of one-hot vectors. (5 –±–∞–ª–ª–æ–≤)\n",
    "- [ ] Visualize similarity distribution for positive vs. negative pairs. (5 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "### ‚úÖ Evaluation & Analysis\n",
    "- [x] Visualize embeddings using t-SNE or UMAP. (3 –±–∞–ª–ª–æ–≤)\n",
    "- [x] Develop and improve beyond accuracy metrics. (5 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "### üìÑ Deliverables\n",
    "- [x] Explain what you changed and why in the final markdown cell. (3 –±–∞–ª–ª–∞)\n",
    "- [x] Keep code modular, clean, and well-documented. (3 –±–∞–ª–ª–∞)\n",
    "\n",
    "### üìù Production\n",
    "- create service based on DSSM vectors with ANN. (8 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "### üìù Leaderboard\n",
    "- Improve score from UserKNN via DSSM (8 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "\n",
    "–ú–∞–∫—Å–∏–º—É–º –±–∞–ª–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å - 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4979b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenii-iurin/work/ITMO-RecSys/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# 2. IMPORTS AND SETUP\n",
    "# ----------------------\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import umap\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b63dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 3. DOWNLOAD AND LOAD DATA\n",
    "# ----------------------\n",
    "def download_and_extract():\n",
    "    url = 'https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip'\n",
    "    filename = 'kion_train.zip'\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        total = int(response.headers.get('content-length', 0))\n",
    "        progress = tqdm(response.iter_content(1024 * 1024),\n",
    "                        f\"Downloading {filename}\",\n",
    "                        total=total // (1024 * 1024), unit='MB')\n",
    "        for chunk in progress:\n",
    "            f.write(chunk)\n",
    "\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")\n",
    "    os.remove(filename)\n",
    "\n",
    "if not os.path.exists(\"data/data_original\"):\n",
    "    download_and_extract()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f578d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 4. DATA PREPROCESSING\n",
    "# ----------------------\n",
    "interactions_df = pd.read_csv('data/data_original/interactions.csv', parse_dates=[\"last_watch_dt\"])\n",
    "users_df = pd.read_csv('data/data_original/users.csv')\n",
    "items_df = pd.read_csv('data/data_original/items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685edb9b",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "–í–º–µ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è one-hot –≤–µ–∫—Ç–æ—Ä–æ–≤ –∑–∞–∫–æ–¥–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Ñ–∏—á—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7327e084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>973171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>962099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1047345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>704055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  sex  kids_flg  user_id\n",
       "0    1       4    2         1   973171\n",
       "1    0       2    2         0   962099\n",
       "2    3       3    1         0  1047345\n",
       "3    3       2    1         0   721985\n",
       "4    2       4    1         0   704055"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input:\n",
    "# - user_df - –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å —é–∑–µ—Ä–∞–º–∏\n",
    "\n",
    "# Oupput:\n",
    "# - user_df - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
    "# - –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ \"unknown\"\n",
    "for col in ['income', 'sex', 'age']:\n",
    "    users_df[col] = users_df[col].fillna('unknown')\n",
    "\n",
    "USERS_FEATURES = [\"age\", \"income\", \"sex\", \"kids_flg\"]\n",
    "users_df = users_df[USERS_FEATURES + [\"user_id\"]]\n",
    "\n",
    "# Encoding\n",
    "user_encoders = {}\n",
    "for feat in USERS_FEATURES:\n",
    "    le = LabelEncoder()\n",
    "    users_df[feat] = le.fit_transform(users_df[feat])\n",
    "    user_encoders[feat] = le\n",
    "\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25a1b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_type</th>\n",
       "      <th>release_year</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>countries</th>\n",
       "      <th>directors</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>258</td>\n",
       "      <td>5671</td>\n",
       "      <td>10711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>421</td>\n",
       "      <td>6546</td>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>298</td>\n",
       "      <td>95</td>\n",
       "      <td>10716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>57</td>\n",
       "      <td>7735</td>\n",
       "      <td>7868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>419</td>\n",
       "      <td>1544</td>\n",
       "      <td>16268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_type  release_year  for_kids  age_rating  studios  countries  \\\n",
       "0             0            86         0           4       33        258   \n",
       "1             0            98         0           4       33        421   \n",
       "2             0            95         0           4       33        298   \n",
       "3             0            99         0           4       33         57   \n",
       "4             0            62         0           3       34        419   \n",
       "\n",
       "   directors  item_id  \n",
       "0       5671    10711  \n",
       "1       6546     2508  \n",
       "2         95    10716  \n",
       "3       7735     7868  \n",
       "4       1544    16268  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input:\n",
    "# - items_df - –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∞–π—Ç–µ–º–∞–º–∏\n",
    "\n",
    "# Oupput:\n",
    "# - items_df - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
    "# - –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ\n",
    "# - –ò–∑–±–∞–≤–ª—è–µ–º—Å—è –æ—Ç NaN –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "\n",
    "ITEMS_FEATURES = ['content_type', 'release_year', 'for_kids', 'age_rating', 'studios', 'countries', 'directors']\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ \"unknown\"\n",
    "for col in ['content_type', 'studios', 'countries', 'directors']:\n",
    "    items_df[col] = items_df[col].fillna('unknown')\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Ñ–∏—á–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (-1)\n",
    "for col in ['release_year', 'for_kids', 'age_rating']:\n",
    "    items_df[col] = items_df[col].fillna(-1)\n",
    "\n",
    "items_df = items_df[ITEMS_FEATURES + ['item_id']]\n",
    "\n",
    "item_encoders = {}\n",
    "for feat in ITEMS_FEATURES:\n",
    "    le = LabelEncoder()\n",
    "    items_df[feat] = le.fit_transform(items_df[feat])\n",
    "    item_encoders[feat] = le\n",
    "\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c42212",
   "metadata": {},
   "source": [
    "–î–ª—è –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏ –ø—Ä–æ–ø–∏—à–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e16833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_categorical_size = {feat: items_df[feat].nunique() for feat in ITEMS_FEATURES}\n",
    "items_features_info = [\n",
    "    (items_categorical_size['content_type'], 8),\n",
    "    (items_categorical_size['release_year'], 8),\n",
    "    (items_categorical_size['for_kids'], 2),\n",
    "    (items_categorical_size['age_rating'], 8),\n",
    "    (items_categorical_size['studios'], 16),\n",
    "    (items_categorical_size['countries'], 8),\n",
    "    (items_categorical_size['directors'], 16),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bbc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_categorical_size = {feat: users_df[feat].nunique() for feat in USERS_FEATURES}\n",
    "users_features_info = [\n",
    "    (users_categorical_size['age'], 16),\n",
    "    (users_categorical_size['income'], 16),\n",
    "    (users_categorical_size['sex'], 2),\n",
    "    (users_categorical_size['kids_flg'], 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9765faf",
   "metadata": {},
   "source": [
    "# –ü—Ä–µ-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥\n",
    "–í —ç—Ç–æ–π —Å–µ–∫—Ü–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –±—ã–ª–æ –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∞ –ª–µ–∫—Ü–∏–∏. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ª–∏—à—å —è–≤–ª—è–µ—Ç—Å—è —Ç–æ, —á—Ç–æ —Ñ–∏—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∞–π—Ç–µ–º–æ–≤ –Ω–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—é—Ç—Å—è –∫–∞–∫ one-hot –≤–µ–∫—Ç–æ—Ä–∞, –ø–æ—Ç–æ–º—É —á—Ç–æ —è –±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å\n",
    "–æ–±—É—á–∞–µ–º—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a3b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# - interactions_df ‚Äî —Å—ã—Ä—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏–ª—å–º–∞–º–∏\n",
    "\n",
    "# Output:\n",
    "# - –û—á–∏—â–µ–Ω–Ω—ã–π interactions_df, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π:\n",
    "#   - –¢–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–≤—à–∏—Ö –±–æ–ª–µ–µ 10 —Ñ–∏–ª—å–º–æ–≤.\n",
    "#   - –¢–æ–ª—å–∫–æ —Ñ–∏–ª—å–º—ã, –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –±–æ–ª–µ–µ —á–µ–º 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏.\n",
    "#   - –¢–æ–ª—å–∫–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è, –≥–¥–µ –ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∏–ª—å–º–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10%.\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
    "# - –£–¥–∞–ª–µ–Ω—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å watched_pct ‚â§ 10%.\n",
    "# - –û—Å—Ç–∞–≤–ª–µ–Ω—ã —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (—Å –±–æ–ª–µ–µ —á–µ–º 10 –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏).\n",
    "# - –û—Å—Ç–∞–≤–ª–µ–Ω—ã —Ç–æ–ª—å–∫–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–∏–ª—å–º—ã (—Å –±–æ–ª–µ–µ —á–µ–º 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏).\n",
    "# - –ò—Ç–æ–≥–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —É–º–µ–Ω—å—à–µ–Ω –≤ –æ–±—ä–µ–º–µ, –Ω–æ –æ—á–∏—â–µ–Ω –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "\n",
    "interactions_df = interactions_df[interactions_df.watched_pct > 10]\n",
    "valid_users = []\n",
    "c = Counter(interactions_df.user_id)\n",
    "for user_id, entries in c.most_common():\n",
    "    if entries > 10:\n",
    "        valid_users.append(user_id)\n",
    "valid_items = []\n",
    "c = Counter(interactions_df.item_id)\n",
    "for item_id, entries in c.most_common():\n",
    "    if entries > 10:\n",
    "        valid_items.append(item_id)\n",
    "\n",
    "interactions_df = interactions_df[interactions_df.user_id.isin(valid_users)]\n",
    "interactions_df = interactions_df[interactions_df.item_id.isin(valid_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5607921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65974\n",
      "6901\n"
     ]
    }
   ],
   "source": [
    "# Input:\n",
    "# - interactions_df ‚Äî –æ—á–∏—â–µ–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ñ–∏–ª—å–º–æ–≤.\n",
    "# - users_df ‚Äî —Ç–∞–±–ª–∏—Ü–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –∏ –∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–ù–ï one-hot).\n",
    "# - items_df ‚Äî —Ç–∞–±–ª–∏—Ü–∞ —Å —Ñ–∏–ª—å–º–∞–º–∏ –∏ –∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–ù–ï one-hot).\n",
    "\n",
    "# Output:\n",
    "# - interactions_df, items_df –∏ users_df ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Ç–æ–ª—å–∫–æ –æ–±—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ñ–∏–ª—å–º—ã.\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
    "# - –ù–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ñ–∏–ª—å–º–æ–≤, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤ interactions_df –∏ users_df/items_df.\n",
    "# - –£–¥–∞–ª–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏ —Ñ–∏–ª—å–º—ã, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ –æ–±–æ–∏—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö.\n",
    "# - –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏ (users_df –∏ items_df).\n",
    "\n",
    "\n",
    "common_users = set(interactions_df.user_id.unique()).intersection(set(users_df.user_id.unique()))\n",
    "common_items = set(interactions_df.item_id.unique()).intersection(set(items_df.item_id.unique()))\n",
    "\n",
    "print(len(common_users))\n",
    "print(len(common_items))\n",
    "\n",
    "interactions_df = interactions_df[interactions_df.item_id.isin(common_items)]\n",
    "interactions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n",
    "\n",
    "items_df = items_df[items_df.item_id.isin(common_items)]\n",
    "users_df = users_df[users_df.user_id.isin(common_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f13bee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65974\n",
      "6897\n"
     ]
    }
   ],
   "source": [
    "common_users = set(interactions_df.user_id.unique()).intersection(set(users_df.user_id.unique()))\n",
    "common_items = set(interactions_df.item_id.unique()).intersection(set(items_df.item_id.unique()))\n",
    "\n",
    "print(len(common_users))\n",
    "print(len(common_items))\n",
    "\n",
    "interactions_df = interactions_df[interactions_df.item_id.isin(common_items)]\n",
    "interactions_df = interactions_df[interactions_df.user_id.isin(common_users)]\n",
    "\n",
    "items_df = items_df[items_df.item_id.isin(common_items)]\n",
    "users_df = users_df[users_df.user_id.isin(common_users)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a5f9a",
   "metadata": {},
   "source": [
    "# –ü–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ : train –∏ test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753646a",
   "metadata": {},
   "source": [
    "### –í—Ä–µ–º–µ–Ω–Ω–æ–π —Å–ø–ª–∏—Ç –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è interaction –º–∞—Ç—Ä–∏—Ü:\n",
    "- –î–µ–ª–∏–º interactions_df –ø–æ –¥–∞—Ç–µ –Ω–∞ train/test –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º N –¥–Ω–µ–π.\n",
    "- –ö–æ–¥–∏—Ä—É–µ–º user_id –∏ item_id –≤ train —á–µ—Ä–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ uid –∏ iid.\n",
    "- –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ—Ç –∂–µ –º–∞–ø–ø–∏–Ω–≥ –∫ test.\n",
    "- –°—Ç—Ä–æ–∏–º interaction –º–∞—Ç—Ä–∏—Ü—ã –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è train –∏ test.\n",
    "- –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏, –∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –±—É–¥—É—â–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54cee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å\n",
    "N_DAYS = 7\n",
    "max_date = interactions_df['last_watch_dt'].max()\n",
    "\n",
    "train_df = interactions_df[interactions_df['last_watch_dt'] <= max_date - pd.Timedelta(days=N_DAYS)]\n",
    "test_df = interactions_df[interactions_df['last_watch_dt'] > max_date - pd.Timedelta(days=N_DAYS)]\n",
    "\n",
    "\n",
    "# –¢–æ–ª—å–∫–æ —é–∑–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –≤ train\n",
    "test_df = test_df[test_df['user_id'].isin(train_df['user_id'])]\n",
    "# –¢–æ–ª—å–∫–æ –∞–π—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –≤ train\n",
    "test_df = test_df[test_df['item_id'].isin(train_df['item_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee628d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: (83707, 7)\n",
      "Train: (1375329, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ –∑–∞–∫–æ–¥–∏—Ä—É–µ–º user_id –∏ item_id –ø–æ train\n",
    "train_df['uid'] = train_df['user_id'].astype('category').cat.codes\n",
    "train_df['iid'] = train_df['item_id'].astype('category').cat.codes\n",
    "\n",
    "# –°–¥–µ–ª–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ user_id –∏ item_id –≤ uid –∏ iid\n",
    "\n",
    "uid_to_user_id = dict(zip(train_df['uid'], train_df['user_id']))\n",
    "iid_to_item_id = dict(zip(train_df['iid'], train_df['item_id']))\n",
    "\n",
    "user_id_to_uid = dict(zip(train_df['user_id'], train_df['uid']))\n",
    "item_id_to_iid = dict(zip(train_df['item_id'], train_df['iid']))\n",
    "\n",
    "# –°–æ–∑–¥–∞–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏ uid –∏ iid –≤ test_df –∏ –ø—Ä–∏–º–µ–Ω–∏–º –º–∞–ø–ø–∏–Ω–≥\n",
    "\n",
    "test_df['uid'] = test_df['user_id'].map(user_id_to_uid)\n",
    "test_df['iid'] = test_df['item_id'].map(item_id_to_iid)\n",
    "\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "print(f\"Train: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ebcd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ –∞–π—Ç–µ–º—ã –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ train\n",
    "\n",
    "items_df = items_df[items_df['item_id'].isin(train_df['item_id'])]\n",
    "items_df = items_df.set_index('item_id').loc[train_df['item_id'].unique()].reset_index()\n",
    "\n",
    "# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–π—Ç–æ–º–æ–≤ –≤ items_df —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–π—Ç–µ–º–æ–≤ –≤ train_df\n",
    "assert items_df.item_id.nunique() == train_df.item_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c32707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ—Ö —é–∑–µ—Ä–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ train\n",
    "\n",
    "users_df = users_df[users_df['user_id'].isin(train_df['user_id'])]\n",
    "users_df = users_df.set_index('user_id').loc[train_df['user_id'].unique()].reset_index()\n",
    "\n",
    "# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤ –≤ users_df —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤ –≤ train_df\n",
    "assert users_df.user_id.nunique() == train_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c88ee7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –º–∞–ø–ø–∏–Ω–≥ –±—ã–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π\n",
    "assert test_df[test_df['uid'] == 4375].user_id.values[0] == train_df[train_df['uid'] == 4375].user_id.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ceea3f",
   "metadata": {},
   "source": [
    "–°–¥–µ–ª–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –∏–Ω—Ç–µ—Ä–∞–∫—Ü–∏—è –¥–ª—è train –∏ test. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b0e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_users = train_df['uid'].nunique()\n",
    "n_items = train_df['iid'].nunique()\n",
    "\n",
    "# ==========================\n",
    "\n",
    "train_vec = np.zeros((n_users, n_items))\n",
    "for uid, iid in zip(train_df['uid'], train_df['iid']):\n",
    "    train_vec[uid, iid] += 1\n",
    "\n",
    "# –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "train_vec = train_vec / train_vec.sum(axis=1, keepdims=True)\n",
    "\n",
    "# ==========================\n",
    "\n",
    "# –¥–ª—è test\n",
    "test_vec = np.zeros((n_users, n_items))\n",
    "for uid, iid in zip(test_df['uid'], test_df['iid']):\n",
    "    test_vec[uid, iid] += 1\n",
    "\n",
    "test_vec = test_vec / test_vec.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f18c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interaction matrix shape : (65792, 6862)\n",
      "Test interaction matrix shape : (65792, 6862)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train interaction matrix shape : {train_vec.shape}\")\n",
    "print(f\"Test interaction matrix shape : {test_vec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd6abfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: –†–∞–∑–º–µ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤ 65792\n",
      "Test: –†–∞–∑–º–µ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤ 25676\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: –†–∞–∑–º–µ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤\", train_df.uid.nunique())\n",
    "print(\"Test: –†–∞–∑–º–µ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —é–∑–µ—Ä–æ–≤\", test_df.uid.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0fe9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FACTORS: 128\n",
      "ITEM_MODEL_SHAPE: (7,)\n",
      "USER_META_MODEL_SHAPE: (4,)\n",
      "USER_INTERACTION_MODEL_SHAPE: (6862,)\n"
     ]
    }
   ],
   "source": [
    "N_FACTORS = 128\n",
    "\n",
    "ITEM_MODEL_SHAPE = (items_df.drop([\"item_id\"], axis=1).shape[1], )\n",
    "USER_META_MODEL_SHAPE = (users_df.drop([\"user_id\"], axis=1).shape[1], )\n",
    "\n",
    "USER_INTERACTION_MODEL_SHAPE = (train_vec.shape[1], )\n",
    "\n",
    "print(f\"N_FACTORS: {N_FACTORS}\")\n",
    "print(f\"ITEM_MODEL_SHAPE: {ITEM_MODEL_SHAPE}\")\n",
    "print(f\"USER_META_MODEL_SHAPE: {USER_META_MODEL_SHAPE}\")\n",
    "print(f\"USER_INTERACTION_MODEL_SHAPE: {USER_INTERACTION_MODEL_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b73bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
